# Проект "Строка" - MVP Backend

## Общее описание
"Строка" - распределённый сервис поиска и рекомендаций на основе обработки естественного языка. Система использует модель машинного обучения для преобразования текстовых запросов в векторные представления и поиска релевантных результатов.

## Архитектура
Проект построен на основе микросервисной архитектуры и состоит из 4-х независимых сервисов:

### 1. Input Gateway (Входная точка)
**Задача:** Принимать запросы пользователей и направлять их в систему.
- Принимает HTTP POST запросы на эндпоинт `/process`
- Перенаправляет запросы в LLM Processor
- Возвращает результаты пользователю

### 2. LLM Processor (Обработчик нейросети)
**Задача:** Преобразовывать текстовые запросы в векторные представления.
- Принимает текстовые запросы от Input Gateway
- Преобразует их в векторы с помощью модели DeepSeek (в MVP используется мок)
- Отправляет векторы в Vector Search

### 3. Vector Search (Векторный поиск)
**Задача:** Искать релевантные результаты по векторам.
- Принимает векторы от LLM Processor
- Выполняет поиск ближайших соседей с помощью FAISS (в MVP используется мок)
- Отправляет найденных кандидатов в Output Formatter

### 4. Output Formatter (Форматирование вывода)
**Задача:** Форматировать и обогащать результаты поиска.
- Принимает список ID кандидатов от Vector Search
- Обогащает их данными из базы данных (в MVP используется мок)
- Форматирует результаты в удобочитаемом виде

## Схема взаимодействия
```
[Пользователь] → [Input Gateway] → [LLM Processor] → [Vector Search] → [Output Formatter] → [Результат]
```

## Технические требования

### Общие для всех микросервисов:
- Python 3.11
- FastAPI для API интерфейсов
- Docker для контейнеризации
- Асинхронная обработка запросов
- Корректная обработка ошибок и таймаутов
- Логирование действий и ошибок

### Специфические требования:
1. **LLM Processor**:
   - Интеграция с API DeepSeek (в продакшене)
   - Векторизация текстовых запросов
   - Оптимизация запросов к языковой модели

2. **Vector Search**:
   - Работа с FAISS индексом (в продакшене)
   - Эффективный поиск ближайших соседей
   - Масштабирование для больших объемов данных

3. **Output Formatter**:
   - Интеграция с базой данных (в продакшене)
   - Различные форматы вывода (текст, HTML, Markdown)
   - Обогащение данных дополнительной информацией

## Запуск проекта
```bash
# Клонирование репозитория
git clone <repository-url>
cd stroka-mvp

# Запуск всех сервисов
docker-compose up --build

# Тестовый запрос
curl -X POST "http://localhost:8000/process" -H "Content-Type: application/json" -d '{"query": "тестовый запрос"}'
```

## Дополнительная документация
Подробное ТЗ по каждому микросервису доступно в соответствующих директориях:
- [input-gateway/README.md](input-gateway/README.md)
- [llm-processor/README.md](llm-processor/README.md)
- [vector-search/README.md](vector-search/README.md)
- [output-formatter/README.md](output-formatter/README.md) 